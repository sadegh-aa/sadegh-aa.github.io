<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sadegh Aliakbarian</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

</head>
<body>
    <header>
        <nav>
            <ul>
                <!-- <li><a href="#about">About</a></li> -->
                <li><a href="#news">News</a></li>
                <li><a href="#publications">Publications</a></li>
            </ul>
        </nav>
    </header>

    <div class="container">
        <section id="about">
        <aside class="sidebar">
            
            <div class="profile">
                <img src="images/pic.png" alt="Profile Photo" class="profile-photo">
                <h1>Sadegh Aliakbarian</h1>
                <p class="intro">
                    I'm a senior research scientist at <a href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-lab-cambridge/">Microsoft Mixed Reality & AI Lab (Cambridge, UK)</a>, working on digital humans and generative modeling of human motion.
                I did my PhD at the <a href="https://www.anu.edu.au/">Australian National University</a>, working on generative modeling of human motion and human activity understanding.
                </p>
                <p style="text-align:center">
                <a href="mailto:s.aliakbarian@gmail.com"><i class="fa fa-envelope-square fa-3x"></i></a> &nbsp &nbsp
                <a href="https://www.linkedin.com/in/sadegh-a/"><i class="fa fa-linkedin-square fa-3x"></i></a> &nbsp &nbsp
                <a href="https://scholar.google.com/citations?user=1qXJQ7cAAAAJ&hl=en"><i class="ai ai-google-scholar-square ai-3x"></i></a> &nbsp &nbsp
                <a href="https://twitter.com/aa_sadegh"><i class="fa fa-twitter-square fa-3x"></i></a>
              </p>
                
            </div>
            
        </aside>
        </section>

        <main class="content">
            <section id="news">
                <h2>Latest News</h2>
                <!-- <ul> -->
                    <i class="fa fa-check-circle"></i>
                Based on the <a href="https://deepgenerativemodels.github.io/">Deep Generative Models</a> lecture by Stefano Ermon, I wrote a <a href="projects/aliakbarian_energy_models_note_2025.pdf">brief tutorial note</a> on energy, score, and diffusion-based models.
                <br>
                <i class="fa fa-check-circle"></i>
                From March 2021, I joined <a href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-lab-cambridge/">Microsoft Mixed Reality and AI Lab-Cambridge</a> (UK) as a research scientist.
                <br>
                <i class="fa fa-check-circle"></i>
                Finished my PhD on <a href="https://openresearch-repository.anu.edu.au/bitstream/1885/213305/1/Ali%20Akbarian_Thesis_2021.pdf">Deep Sequence Learning for Video Anticipation</a> at the Australian National University.
                <br>
              <i class="fa fa-check-circle"></i>
                Selected for <a href="http://cvpr2020.thecvf.com/reviewer-acknowledgements">Outstanding Reviewer Award</a> at CVPR 2020.
                <br><br><br>

                <!-- </ul> -->
            </section>

            <section id="publications">
                <h2>Publications</h2>
                <h4>2025</h4>
    <div class="publication-card">
  <div class="publication-thumbnail">
    <img src="papers/david_2025.png" alt="Project Thumbnail">
  </div>
  <div class="publication-content">
    <h4><a href="https://microsoft.github.io/DAViD/">DAVID: Data-efficient and Accurate Vision Models from Synthetic Data</a></h4>
    <p>Fatemeh Saleh, <b>Sadegh Aliakbarian</b>, Charlie Hewitt, Lohit Petikam, Xiao-Xian, Antonio Criminisi, Thomas J. Cashman, Tadas Baltru≈°aitis</p>
    <p><em>International Conference on Computer Vision (ICCV), 2025</em></p>
    <div class="links">
        <a href="https://microsoft.github.io/DAViD/">project page</a> /
        <a href='https://arxiv.org/abs/2507.15365'>arXiv</a> /
        <a href="https://youtu.be/FQtHC5e1dDg">Video</a> /
        <a href="https://github.com/microsoft/DAViD">code</a>
    </div>
  </div>
</div>
    <div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/3DiFACE_2025.png" alt="3DiFACE Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://balamuruganthambiraja.github.io/3DiFACE/">3DiFACE: Diffusion-based Speech-driven 3D Facial Animation and Editing</a></h4>
        <p>Balamurugan Thambiraja, <b>Sadegh Aliakbarian</b>, Darren Cosker, Justus Thies</p>
        <p><em>International Conference on 3D Vision (3DV), 2025</em></p>
        <div class="links">
            <a href="https://balamuruganthambiraja.github.io/3DiFACE/">project page</a> /
            <a href='https://arxiv.org/abs/2312.00870'>arXiv</a> /
            <a href="https://www.youtube.com/watch?v=Mep5pAU3TPc">Video</a> /
            <a href="https://github.com/bala1144/3DiFACE">code</a>
        </div>
    </div>
</div>

<h4>2024</h4>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/lookma_2024.png" alt="SynthMoCap Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://microsoft.github.io/SynthMoCap/">Look Ma, no markers: holistic performance capture without the hassle</a></h4>
        <p>Charlie Hewitt, Fatemeh Saleh, <b>Sadegh Aliakbarian</b>, Lohit Petikam, Shideh Rezaeifar, Louis Florentin, Zafiirah Hosenie, Thomas J Cashman, Julien Valentin, Darren Cosker, Tadas Baltrusaitis</p>
        <p><em>ACM Transactions on Graphics (TOG) / SIGGRAPH Asia, 2024</em></p>
        <div class="links">
            <a href="https://microsoft.github.io/SynthMoCap/">project page</a> /
            <a href='https://arxiv.org/pdf/2410.11520'>arXiv</a> /
            <a href="https://youtu.be/4RkLDW3GmdY">Video</a> /
            <a href="https://github.com/microsoft/SynthMoCap">code</a>
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/simpleEgo_2024.png" alt="SimpleEgo Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://arxiv.org/abs/2401.14785">SimpleEgo: Predicting probabilistic body pose from egocentric cameras</a></h4>
        <p>Hanz Cuevas Velasquez, Charlie Hewitt, <b>Sadegh Aliakbarian</b>, Tadas Baltrusaitis</p>
        <p><em>International Conference on 3D Vision (3DV), 2024</em></p>
        <div class="links">
            <a href="https://microsoft.github.io/SimpleEgo/">project page</a> /
            <a href='https://arxiv.org/abs/2401.14785'>arXiv</a> /
            Video /
            <a href="https://github.com/microsoft/SimpleEgo">code</a>
        </div>
    </div>
</div>

<h4>2023</h4>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/HMD_Nemo_2023.png" alt="HMD-NeMo Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://openaccess.thecvf.com/content/ICCV2023/html/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.html">HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations</a></h4>
        <p><b>Sadegh Aliakbarian</b>, Fatemeh Saleh, David Collier, Pashmina Cameron, Darren Cosker</p>
        <p><em>International Conference on Computer Vision (ICCV), 2023</em></p>
        <div class="links">
            project page /
            arXiv /
            Video /
            code
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/imitator_2023.png" alt="Imitator Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://arxiv.org/abs/2301.00023">Imitator: Personalized Speech-driven 3D Facial Animation</a></h4>
        <p>Balamurugan Thambiraja, Ikhsanul Habibie, <b>Sadegh Aliakbarian</b>, Darren Cosker, Christian Theobalt, Justus Thies</p>
        <p><em>International Conference on Computer Vision (ICCV), 2023</em></p>
        <div class="links">
            <a href="https://balamuruganthambiraja.github.io/Imitator">project page</a> /
            <a href="https://arxiv.org/abs/2301.00023">arXiv</a> /
            Video /
            code
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/egoHMR_2023.png" alt="Probabilistic Human Mesh Recovery Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://sanweiliti.github.io/egohmr/egohmr.html">Probabilistic Human Mesh Recovery in 3D Scenes from Egocentric Views</a></h4>
        <p>Siwei Zhang, Qianli Ma, Yan Zhang, <b>Sadegh Aliakbarian</b>, Darren Cosker, Siyu Tang</p>
        <p><em>International Conference on Computer Vision (ICCV), 2023 <b>(Oral Presentation)</b></em></p>
        <div class="links">
            <a href="https://sanweiliti.github.io/egohmr/egohmr.html">project page</a> /
            <a href="https://arxiv.org/abs/2304.06024">arXiv</a> /
            <a href="https://youtu.be/Fh5vtB2pbq0">Video</a> /
            <a href="https://github.com/sanweiliti/EgoHMR">code</a>
        </div>
    </div>
</div>

<h4>2022</h4>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/flag_2022.png" alt="FLAG Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://arxiv.org/abs/2203.05789">FLAG: Flow-based Avatar Generation from Sparse Observations</a></h4>
        <p><b>Sadegh Aliakbarian</b>, Pashmina Cameron, Federica Bogo, Andew Fitzgibbon, Thomas J. Cashman</p>
        <p><em>International Conference on Computer Vision and Pattern Recognition (CVPR), 2022</em></p>
        <div class="links">
            <a href="https://microsoft.github.io/flag/"> project page</a> /
            <a href="https://arxiv.org/abs/2203.05789">arXiv</a> /
            <a href="https://www.youtube.com/watch?v=ZgkJ_TD_CRI">Talk</a> /
            code
        </div>
    </div>
</div>

<h4>2021</h4>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/lcp_2021.png" alt="Contextually Plausible and Diverse 3D Human Motion Prediction Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://arxiv.org/abs/1912.08521v4">Contextually Plausible and Diverse 3D Human Motion Prediction</a></h4>
        <p><b>Sadegh Aliakbarian</b>, Fatemeh Saleh, Lars Petersson, Stephen Gould, Mathieu Salzmann</p>
        <p><em>International Conference on Computer Vision (ICCV), 2021 <b>(Oral Presentation)</b></em></p>
        <div class="links">
            project page /
            <a href="https://arxiv.org/pdf/1912.08521v4.pdf">arXiv</a> /
            video /
            code
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/artist_2021.png" alt="Probabilistic Tracklet Scoring Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://arxiv.org/pdf/2012.02337">Probabilistic Tracklet Scoring and Inpainting for Multiple Object Tracking</a></h4>
        <p>Fatemeh Saleh, <b>Sadegh Aliakbarian</b>, Hamid Rezatofighi, Mathieu Salzmann, Stephen Gould</p>
        <p><em>Proceedings of the IEEE international conference on computer vision (CVPR), 2021 <b>(Oral Presentation)</b></em></p>
        <div class="links">
            project page /
            <a href="https://arxiv.org/pdf/2012.02337">arXiv</a> /
            video /
            <a href="https://github.com/fatemeh-slh/ArTIST">code</a>
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/paper_logo.png" alt="Multi-FAN Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://link.springer.com/article/10.1007/s00138-021-01174-w">Multi-FAN: Multi-Spectral Mosaic Super-Resolution Via Multi-Scale Feature Aggregation Network</a></h4>
        <p>Mehrdad Shoeiby, <b>Sadegh Aliakbarian</b>, Saeed Anwar and Lars petersson</p>
        <p><em>Machine Vision and Applications (MVA), 2021</em></p>
        <div class="links">
            project page /
            <a href="https://arxiv.org/pdf/1807.03528.pdf">arXiv</a> /
            video /
            code
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/saliency_2021.png" alt="Uncertainty Inspired RGB-D Saliency Detection Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://arxiv.org/abs/2009.03075">Uncertainty Inspired RGB-D Saliency Detection</a></h4>
        <p>Jing Zhang, Deng-Ping Fan, Yuchao Dai, Saeed Anwar, Fatemeh Saleh, <b>Sadegh Aliakbarian</b>, Nick Barnes</p>
        <p><em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021</em></p>
        <div class="links">
            project page /
            <a href="https://arxiv.org/pdf/2009.03075.pdf">arXiv</a> /
            video /
            <a href="https://github.com/JingZhang617/UCNet">code</a>
        </div>
    </div>
</div>

<h4>2020</h4>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/mix_and_match_2020.png" alt="Stochastic Conditioning Scheme Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Aliakbarian_A_Stochastic_Conditioning_Scheme_for_Diverse_Human_Motion_Prediction_CVPR_2020_paper.html">A Stochastic Conditioning Scheme for Diverse Human Motion Prediction</a></h4>
        <p><b>Sadegh Aliakbarian</b>, Fatemeh Saleh, Mathieu Salzmann, Lars Petersson, Stephen Gould</p>
        <p><em>Proceedings of the IEEE international conference on computer vision (CVPR), 2020</em></p>
        <div class="links">
            <a href="https://mix-and-match.github.io/">project page</a> /
            <a href="https://mix-and-match.github.io/media/MixMatch.pdf">arXiv</a> /
            <a href="https://www.youtube.com/watch?v=2kmihoa8xLA">video</a> /
            <a href="https://github.com/mix-and-match/mix-and-match-tutorial">code</a>
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/paper_logo.png" alt="Super-resolved Chromatic Mapping Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="http://openaccess.thecvf.com/content_WACV_2020/papers/Shoeiby_Super-resolved_Chromatic_Mapping_of_Snapshot_Mosaic_Image_Sensors_via_a_WACV_2020_paper.pdf">Super-resolved Chromatic Mapping of Snapshot Mosaic Image Sensors via a Texture Sensitive Residual Network</a></h4>
        <p>Mehrdad Shoeiby, Lars Petersson, Ali Armin, <b>Sadegh Aliakbarian</b></p>
        <p><em>Winter Conference on Applications of Computer Vision (WACV), 2020</em></p>
        <div class="links">
            project page /
            <a href="http://openaccess.thecvf.com/content_WACV_2020/papers/Shoeiby_Super-resolved_Chromatic_Mapping_of_Snapshot_Mosaic_Image_Sensors_via_a_WACV_2020_paper.pdf">arXiv</a> /
            Video /
            Code
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/paper_logo.png" alt="Mosaic Super-resolution Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://www.researchgate.net/profile/Saeed_Anwar16/publication/338238878_Mosaic_Super-resolution_via_Sequential_Feature_Pyramid_Networks/links/5e1d157a299bf10bc3abe5f5/Mosaic-Super-resolution-via-Sequential-Feature-Pyramid-Networks.pdf">Mosaic Super-resolution via Sequential Feature Pyramid Networks</a></h4>
        <p>Mehrdad Shoeiby, Ali Armin, <b>Sadegh Aliakbarian</b>, Saeed Anwar, Lars Petersson</p>
        <p><em>Proceedings of the IEEE international conference on computer vision Workshops (CVPRW), 2020</em></p>
        <div class="links">
            project page /
            <a href="https://www.researchgate.net/profile/Saeed_Anwar16/publication/338238878_Mosaic_Super-resolution_via_Sequential_Feature_Pyramid_Networks/links/5e1d157a299bf10bc3abe5f5/Mosaic-Super-resolution-via-Sequential-Feature-Pyramid-Networks.pdf">arXiv</a> /
            Video /
            Code
        </div>
    </div>
</div>

<h4>2019</h4>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/paper_logo.png" alt="Sampling Good Latent Variables Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://arxiv.org/pdf/1912.08521.pdf">Sampling Good Latent Variables via CPP-VAEs: VAEs with Condition Posterior as Prior</a></h4>
        <p><b>Sadegh Aliakbarian</b>, Fatemeh Saleh, Mathieu Salzmann, Lars Petersson, Stephen Gould</p>
        <p><em>ArXiv, 2019</em></p>
        <div class="links">
            project page /
            <a href="https://arxiv.org/pdf/1912.08521.pdf">arXiv</a> /
            Video /
            Code
        </div>
    </div>
</div>

<h4>2018</h4>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/viena.png" alt="VIENA2 Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://link.springer.com/chapter/10.1007/978-3-030-20887-5_28">VIENA2: A Driving Anticipation Dataset</a></h4>
        <p><b>Sadegh Aliakbarian</b>, Fatemeh Saleh, Mathieu Salzmann, Basura Fernando, Lars Petersson, Lars Andersson</p>
        <p><em>Asian Conference on Computer Vision (ACCV), 2018</em></p>
        <div class="links">
            <a href="https://sites.google.com/view/viena2-project/home">project page</a> /
            <a href="https://arxiv.org/pdf/1810.09044.pdf">arXiv</a> /
            Video /
            <a href="https://sites.google.com/view/viena2-project/home">Code</a>
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/veis.png" alt="Effective Use of Synthetic Data Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://link.springer.com/chapter/10.1007/978-3-030-01216-8_6">Effective Use of Synthetic Data in Urban Scene Semantic Segmentation</a></h4>
        <p>Fatemeh Saleh, <b>Sadegh Aliakbarian</b>, Mathieu Salzmann, Lars Petersson, Jose M Alvarez</p>
        <p><em>European Conference on Computer Vision (ECCV), 2018</em></p>
        <div class="links">
            <a href="https://github.com/fatemeh-slh/VEIS">project page</a> /
            <a href="https://arxiv.org/pdf/1807.06132.pdf">arXiv</a> /
            Video /
            <a href="https://github.com/fatemeh-slh/VEIS">Code</a>
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/incorporating.png" alt="Incorporating Network Built-in Priors Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://ieeexplore.ieee.org/abstract/document/7944591/">Incorporating Network Built-in Priors in Weakly-supervised Semantic Segmentation</a></h4>
        <p>Fatemeh Saleh, <b>Sadegh Aliakbarian</b>, Mathieu Salzmann, Lars Petersson, Jose M Alvarez, Stephen Gould</p>
        <p><em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2018</em></p>
        <div class="links">
            project page /
            <a href="https://arxiv.org/pdf/1706.02189.pdf">arXiv</a> /
            Video /
            Code
        </div>
    </div>
</div>

<h4>2017</h4>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/encouraging.png" alt="Encouraging LSTMs to Anticipate Actions Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Aliakbarian_Encouraging_LSTMs_to_ICCV_2017_paper.pdf">Encouraging LSTMs to Anticipate Actions Very Early</a></h4>
        <p><b>Sadegh Aliakbarian</b>, Fatemeh Saleh, Mathieu Salzmann, Basura Fernando, Lars Petersson, Lars Andersson</p>
        <p><em>International Conference on Computer Vision (ICCV), 2017</em></p>
        <div class="links">
            project page /
            <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Aliakbarian_Encouraging_LSTMs_to_ICCV_2017_paper.pdf">arXiv</a> /
            Video /
            Code
        </div>
    </div>
</div>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/fgbg.png" alt="Bringing background into the foreground Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://ieeexplore.ieee.org/abstract/document/8237494">Bringing background into the foreground: Making all classes equal in weakly-supervised video semantic segmentation</a></h4>
        <p>Fatemeh Saleh, <b>Sadegh Aliakbarian</b>, Mathieu Salzmann, Lars Petersson, Jose M Alvarez</p>
        <p><em>International Conference on Computer Vision (ICCV), 2017</em></p>
        <div class="links">
            project page /
            <a href="https://arxiv.org/pdf/1708.04400.pdf">arXiv</a> /
            Video /
            Code
        </div>
    </div>
</div>

<h4>2016</h4>
<div class="publication-card">
    <div class="publication-thumbnail">
        <img src="papers/builtinprior.png" alt="Built-in Foreground/Background Prior Thumbnail">
    </div>
    <div class="publication-content">
        <h4><a href="https://link.springer.com/chapter/10.1007/978-3-319-46484-8_25">Built-in Foreground/Background Prior for Weakly-Supervised Semantic Segmentation</a></h4>
        <p>Fatemeh Saleh, <b>Sadegh Aliakbarian</b>, Mathieu Salzmann, Lars Petersson, Stephen Gould, Jose M Alvarez</p>
        <p><em>European Conference on Computer Vision (ECCV), 2016</em></p>
        <div class="links">
            project page /
            <a href="https://arxiv.org/pdf/1609.00446.pdf">arXiv</a> /
            Video /
            Code
        </div>
    </div>
</div>
            </section>
        </main>
    </div>

    <footer>
        <p>&copy; 2025 Sadegh Aliakbarian</p>
    </footer>
</body>
</html>
